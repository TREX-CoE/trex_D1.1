\newcommand{\orgmode}{\texttt{org-mode}}
\newcommand{\Makefile}{\mintinline{shell}{Makefile}}
\newcommand{\context}{\mintinline{shell}{context}}
\newcommand{\CC}{C\nolinebreak\hspace{-.05em}\raisebox{.4ex}{\tiny\bf +}\nolinebreak\hspace{-.10em}\raisebox{.4ex}{\tiny\bf +}}
\def\CC{{C\nolinebreak[4]\hspace{-.05em}\raisebox{.4ex}{\tiny\bf ++}}}

\section{Introduction}


The ultimate goal of \ac{QMCkl} is to provide a high-performance
implementation of the main kernels of \ac{QMC}. In this particular
\ac{WP}, we focus on the definition of the \ac{API}, the tests,
and on a \emph{pedagogical} presentation of the algorithms.  We expect
the \ac{HPC} experts to use this repository as a reference for re-writing
optimized versions of the functions described in this library, using
the same \ac{API}.

The documentation of the current status of the library is available
at \url{https://trex-coe.github.io/qmckl}, and the source code is
available on the GitHub repository at \url{https://github.com/trex-coe/qmckl}.


\subsection{Literate programming}

In a traditional code, most of the lines of source files are code,
scripts, {\Makefile}s, and only a few lines are comments explaining
parts of the code that are non-trivial to understand. The
documentation of the prorgam is usually written in a separate
directory, and is often outdated with respect to the current version
of the code.

Literate programming\cite{knuth_1992} is a different approach to
programming, where the program is considered as a publishable-quality
document. Most of the lines of the source files are text,
mathematical formulas, tables, figures, \textit{etc}, and the lines of
code are just the translation in a computer language of the ideas
and algorithms expressed in the text. More importantly, the ``document'' is
structured like a text document with sections, subsections, a bibliography,
a table of contents \textit{etc}. The place where pieces of code
appear are the places where they should belong for the reader to
understand the logic of the program, not the places where the compiler
expects to find them. Both the publishable-quality document and the
binary executable are produced from the same source files. 

Literate programming is particularly well adapted in this context, as
the central part of this project is the documentation of an
\ac{API}. The implementation of the algorithms is just an expression
of the algorithms in a language that can be compiled, so that the
correctness of the algorithms can be tested.

We have chosen to write the source files in {\orgmode}
format,\cite{schulte_2012,orgmode} as any text editor can be used to
edit {\orgmode} files. To produce the documentation, there exists
multiple possibilities to convert {\orgmode} files into different
formats such as \ac{HTML} or \ac{PDF}. The source code is easily
extracted from the {\orgmode} files invoking the Emacs text editor
from the command-line in the {\Makefile}, and then the produced files
are compiled as usual.  Moreover, within the Emacs text editor the
source code blocks can be executed interactively, as in Jupyter
notebooks,\cite{Kluyver_2016} but with the advantage that multiple
languages can be used in the same notebook.

\section{Source code}

\subsection{Choice of the programming language}

Most of the codes of the \ac{TREX} \ac{CoE} are written in Fortran
with some scripts in Bash and Python. Outside of the
\ac{CoE}, Fortran is also important (Casino, Amolqc), and other
important languages used by the community are C and {\CC} (QMCPack,
QWalk). Python is very popular for prototyping, and Julia is gaining
in popularity.\cite{poole_2020} The library we design should be
compatible with at least all of these languages. A simple solution is
to provide a C-compatible \ac{API} since all these languages have a
\ac{FFI} for calling functions written in C, especially for
interacting with the operating system.

High-performance versions of the \ac{QMCkl}, with the same \ac{API},
will be rewritten in \ac{WP}3 by the experts in \ac{HPC}. These
optimized libraries will be tuned for specific architectures, among
which we can cite x86 based processors and \ac{GPU} accelerators.
Nowadays, the most efficient software tools to take advantage of
low-level features of the processor (intrinsics) and of \acp{GPU} are
for {\CC} developers. It is highly probable that some optimized
implementations will be written in {\CC}, and this is agreement with our
choice to make the \ac{API} C-compatible.

Fortran is one of the most common languages used by the community, and
is simple enough to make the algorithms readable both by experts in
\ac{QMC}, and experts in \ac{HPC}. Hence we propose in this
pedagogical implementation of \ac{QMCkl} to use Fortran to express the
QMC algorithms, but we expose them through the \ac{API} as if they
were written in C using the \mintinline{fortran}{iso_c_binding} \ac{FFI}.

To avoid collisions in the names of the compiled files, the names of
the Fortran source files end with \mintinline{shell}{_f.f90}, and Fortran
interface files end with \mintinline{shell}{_fh.f90}.
The names of the functions defined in Fortran should be the
same as those exposed in the \ac{API} suffixed by \mintinline{shell}{_f}.

When the library is built, a single shared library is produced
(\mintinline{shell}{libqmckl.so}). All the function prototypes are given in a single C
header file \mintinline{shell}{qmckl.h}, and a Fortran interface to the library
is provided via a module containing only interfaces to the C functions
(\mintinline{shell}{qmckl_f.f90}).


\subsection{Packaging}

We intend to use the GNU build system, Autotools,\cite{autotools} for
configuration and installation scripts.
Although there exists more modern build tools, we have chosen a
solution that will be easy for the end user, and which is one of the
most reliable in terms of portability among different architectures.

In the future, we plan to provide \texttt{.deb} and \texttt{.rpm}
packages for the most common Linux distributions, as well as a package
for the Spack package manager.\cite{spack}

\section{Design of the library}

The proposed \ac{API} should allow the library to deal with memory
transfers between CPU and accelerators, and to use dynamically
different levels of floating-point precision.  We chose a
multi-layered design with low-level and high-level functions (see
below).

\subsection{Naming conventions}

To avoid namespace collisions, we use \mintinline{C}{qmckl_} as a prefix for
all exported functions and variables.  All exported header files
should have a file name prefixed with \mintinline{shell}{qmckl_}.

For instance, if the name of the {\orgmode} file is
\mintinline{shell}{xxx.org}, the name of the produced C files should
be \mintinline{shell}{xxx.c} and \mintinline{shell}{xxx.h} and the
name of the produced Fortran file should be
\mintinline{shell}{xxx.f90}

Arrays are in uppercase and scalars are in lowercase.

In the  names of  the variables and  functions, only the singular
form is allowed.

\subsection{Application programming interface}

In the C language, the number of bits used by the integer types can
change from one architecture to another one. To circumvent this
problem, we choose to use the integer types defined in
\mintinline{C}{<stdint.h>} where the number of bits used for the
integers are fixed.

To ensure that the library will be easily usable in \emph{any} other
language than C, we restrict the data types in the interfaces to the
following:
\begin{itemize}
\item 32-bit and 64-bit integers, scalars and and arrays
  (\mintinline{C}{int32_t} and \mintinline{C}{int64_t})
\item 32-bit and 64-bit floats, scalars and and arrays
  (\mintinline{C}{float} and \mintinline{C}{double})
\item Pointers are always casted into 64-bit integers, even on legacy 32-bit architectures
\item ASCII strings are represented as a pointers to character arrays
  and terminated by a zero character (C convention).
\item Complex numbers can be represented by an array of 2 floats.
\item Boolean variables are stored as integers, \mintinline{C}{1} for
\mintinline{C}{true} and \mintinline{C}{0} for \mintinline{C}{false}
\item Floating point variables should be by default
\mintinline{C}{double}, unless explicitly mentioned
\item integers used for counting should always be \mintinline{C}{int64_t}
\end{itemize}

To facilitate the  use in other languages than C, we will provide some
bindings in other languages in other repositories.


\subsubsection{Global state}

Global variables should  be avoided in the library,  because it is
possible that one  single program needs to  use multiple instances
of the library. To solve this  problem we propose to use a pointer
to a {\context}  variable,  built   by  the  library   with  the
\mintinline{C}{qmckl_context_create} function. The
{\context} contains the global state of the library, and is used as
the first argument of many \ac{QMCkl} functions.

The internal structure of the {\context}  is not specified, to give a
maximum of  freedom to  the different  implementations.  Modifying
the  state   is  done   by  setter   and  getter functions,   prefixed  by
\mintinline{C}{qmckl_context_set_}  an
\mintinline{C}{qmckl_context_get_}.
When a {\context} variable is modified by a setter, a copy of the old
data structure is made and updated, and the pointer to the new data
structure is returned, such that the old contexts can still be
accessed.  It is also possible to modify the state in an mutable
fashion, using the \mintinline{C}{qmckl_context_update_} functions.
The {\context} and its old versions can be destroyed with
\mintinline{C}{qmckl_context_destroy}.


\subsubsection{Low-level functions}

Low-level functions are very simple  functions which are leaves of
the function call tree (they don't call any other \ac{QMCkl} function).

These  functions   are   \emph{pure},   and  unaware   of   the   \ac{QMCkl}
{\context}. They are not allowed to allocate/deallocate memory, and
if they need temporary memory it should be provided in input.

\subsubsection{Numerical precision}

The number of bits of precision  required for a function should be
given as an input of low-level computational functions. This input
will be used to define the values of the different thresholds that
might be  used to  avoid computing unnecessary  noise.  High-level
functions  will  use  the  precision specified  in  the  \texttt{context}
variable.

\subsubsection{High-level functions}

High-level functions  are at  the top of  the function  call tree.
They  are  able  to  choose which  lower-level  function  to  call
depending on the required precision, and do the corresponding type
conversions.  These functions are  also responsible for allocating
temporary storage, to simplify the use of accelerators.

The high-level  functions should be pure,  unless the introduction
of non-purity is justified. All the side effects should be made in
the \texttt{context} variable.


\subsection{Algorithms}

Reducing the scaling of an  algorithm usually implies also reducing
its arithmetic  complexity (number  of flops per  byte). Therefore,
for  small  sizes   \(\mathcal{O}(N^3)\)  and  \(\mathcal{O}(N^2)\)
algorithms are  better adapted than linear  scaling algorithms.  As
\ac{QMCkl} is a  general purpose library, multiple  algorithms will be
implemented adapted to different problem sizes.



\section{Codesign}
\label{sec:codesign}

Research codes are developed over a long period of time by multiple
researchers, Ph.D students and post-docs. The professional evaluation
of these people is based on their scientific production and not on the
quality of the software they write, so code quality and refactoring is
often left in the low-priority tasks. As a consequence, research
codes often depend on some choices made at an immature stage of the
program, and solutions to bypass the wrong choices make the code
complicated to understand for external people, especially if they are
not familiar with the domain.

\subsection{Kernel extraction}

The strategy we have chosen to extract the kernels of the codes is to
first discuss among the developers of \ac{QMC} codes to understand how they have
implemented each particular kernel. Once the developers have agreed on
which algorithm is best, they first formulate the algorithm in terms
of mathematical expressions in a {\LaTeX} file, and they create a prototype application 
(the \emph{mini-application}) implementing \emph{only} the kernel of
interest. This mini-application can be easily compiled and executed,
and is considered valid when it reproduces exactly the values obtained
with the kernel present in the original \ac{QMC} code.

The mini-application is then thoroughy modified together with the
\ac{HPC} experts involved in \ac{WP}3 until the optimal data
strtuctures and algorithms are determined. This step is crucial to
facilitate the access to performance in the \ac{HPC} versions of the
library that will be developed in \ac{WP}3.  Once the \ac{QMC} and
\ac{HPC} specialists have agreed on the data structures, the kernel is
ready to be implemented in the
library.


\subsection{A concrete example}

The first kernel we have been working on is the three-body component of
the Jastrow factor, which is one of the potential bottlenecks of
extreme-scale calculations that will run on exascale machines.
In the CHAMP program, it is expressed as

\newcommand{\Jeen}{J_{\text{een}}}
\newcommand{\Nel}{N_{\text{elec}}}
\newcommand{\Nat}{N_{\text{nucl}}}
\newcommand{\Nord}{N_{\text{nord}}}
\newcommand{\lmax}{p-k-2\delta_{k,0}}
\newcommand{\br}{\mathbf{r}}
\newcommand{\bR}{\mathbf{R}}
\[
  \Jeen (\br,\bR) = \sum_{\alpha=1}^{\Nat} \sum_{i=1}^{\Nel} \sum_{j=1}^{i-1}
\sum_{p=2}^{\Nord} \sum_{k=0}^{p-1}
\sum_{l=0}^{\lmax} c_{lkp\alpha}
\left( {r}_{ij} \right)^k
\left[ \left( {R}_{i\alpha} \right)^l + \left( {R}_{j\alpha} \right)^l \right]
\left( {R}_{i\,\alpha} \, {R}_{j\alpha} \right)^{(p-k-l)/2} 
\]
where
$\Nel$ is the number of electrons, 
$\Nat$ is the number of nuclei,
$\Nord$ is the maximum order of the polynomial, 
$\br$ contains rescaled electron-electron distances, 
$\bR$ contains rescaled electron-nucleus distances,
and $c_{lkp\alpha}$ are the variational parameters which are non-zero
only when $p-k-l$ is even.

For \ac{QMC} simulations, the first and second derivatives of $\Jeen$ with
respect to the electron coordinates are also required. To optimize the
parameters, the derivative with respect to $c_{lkp\alpha}$
should also be available, and in the context of molecular dynamics or
geometry optimization the first derivatives with respect to $\bR$ are
also required. To compute these derivatives, multiple intermediates
will be common and we need to identify them such that the same
intermediates can be reused for several derivatives.

We have rewritten a mini-application to implement the three-body component
of the Jastrow factor, as well as the first and second derivative with
respect to electron coordinates. This mini-application, available on
GitHub\footnote{\url{https://github.com/trex-coe/irpjast}} has allowed us to
rewrite the expressions in a way allowing us to take advantage of BLAS3
matrix multiplication. The expression is now expressed in terms of
rank-3 and rank-4 tensors
\newcommand{\tr}{\, \bar{\mathtt{r}}}
\newcommand{\tR}{\, \bar{\mathtt{R}}}
\newcommand{\tP}{\, \bar{\mathtt{P}}}
\[
  \Jeen(\br,\bR) = 
  \sum_{p=2}^{\Nord}\sum_{k=0}^{p-1}
  \sum_{l=0}^{\lmax} 
    \sum_{\alpha=1}^{\Nat}
    c_{lkp\alpha}
    \sum_{i=1}^{\Nel}
    {\tR}_{i,\alpha,(p-k-l)/2}\,
  {\tP}_{i,\alpha,k,(p-k+l)/2}
  \]
with 
  \[
  {\tP}_{i, \alpha, k, l} = \sum_{j=1}^{\Nel} {\tr}_{i,j,k}\,{\tR}_{j,\alpha,l}.
  \]
  
Similarly, the gradient with respect to electron coordinates and the
Laplacian require an additional intermediate and reuses ${\tP}$. As
the gradient ($\nabla_{i}$) and the Laplacian ($\Delta_i$) have a
large part of their expression in common, the $3\Nel$ components of
the gradient and the $\Nel$ components of the Laplacian are stored in
the same tensor, adding an extra index $m=(1,2,3)$ for $\nabla_x,
\nabla_y,\nabla_z$
and $m=4$ for $\Delta$.

\newcommand{\tg}{\, \bar{\mathtt{g}}}
\newcommand{\tG}{\, \bar{\mathtt{G}}}
\newcommand{\tQ}{\, \bar{\mathtt{Q}}}

\begin{eqnarray*}
  \nabla_{im} \Jeen(\br,\bR) & = &
  \sum_{p=2}^{\Nord}\sum_{k=0}^{p-1}
  \sum_{l=0}^{\lmax} 
    \sum_{\alpha=1}^{\Nat}
    c_{lkp\alpha}
    \sum_{i=1}^{\Nel} 
     {\tG}_{i,m,\alpha,(p-k-l)/2} {\tP}_{i,\alpha,k,(p-k+l)/2} +  \\
&&   {\tG}_{i,m,\alpha,(p-k+l)/2} {\tP}_{i,\alpha,k,(p-k-l)/2} + 
     {\tR}_{i,\alpha,(p-k-l)/2} {\tQ}_{i,m,\alpha,k,(p-k+l)/2} + \\
&&   {\tR}_{i,\alpha,(p-k+l)/2} {\tQ}_{i,m,\alpha,k,(p-k-l)/2} + 
    \delta_{m,4} \big( \\
&&     {\tG}_{i,1,\alpha,(p-k+l)/2} {\tQ}_{i,1,\alpha,k,(p-k-l)/2} +
       {\tG}_{i,2,\alpha,(p-k+l)/2} {\tQ}_{i,2,\alpha,k,(p-k-l)/2} + \\
&&     {\tG}_{i,3,\alpha,(p-k+l)/2} {\tQ}_{i,3,\alpha,k,(p-k-l)/2} +
       {\tG}_{i,1,\alpha,(p-k-l)/2} {\tQ}_{i,1,\alpha,k,(p-k+l)/2} + \\
&&     {\tG}_{i,2,\alpha,(p-k-l)/2} {\tQ}_{i,2,\alpha,k,(p-k+l)/2} + 
       {\tG}_{i,3,\alpha,(p-k-l)/2} {\tQ}_{i,3,\alpha,k,(p-k+l)/2} \big)
\end{eqnarray*}
with 
\[
  {\tG}_{i, m, \alpha, l}  =  \frac{\partial \left( {R}_{i\alpha} \right)^l}
                             {\partial r_i},  \phantom{ space }
  {\tg}_{i, m, j, k}  =  \frac{\partial \left( {r}_{ij} \right)^k}
                             {\partial r_i}, \phantom{ space }
                             \text{ and } 
  {\tQ}_{i, m, \alpha, k, l}  =  \sum_{j=1}^{\Nel}
                            {\tg}_{i,m,j,k}\,{\tR}_{j,\alpha,l} 
\]
  
\begin{figure}[t]
  \begin{center}
  \includegraphics[width=0.75\textwidth]{speedup.pdf}
  \end{center}
  \caption{\label{fig:speedup}Speedup obained after the re-expression of the three-body
    Jastrow factor.}
\end{figure}

This rewriting allowed us to move the computationally intensive part in
$\mathcal{O}(\Nat{\Nel}^2)$, i.e. the construction of the intermediate
tensors, into a BLAS3 matrix multiplication, the remaining part being
in $\mathcal{O}(\Nat \Nel)$.

The performance of the computation of the value, gradient and Laplacian of
the three-body Jastrow factor was measured on an Intel(R) Xeon(R) Gold
6130 processor, and the code was compiled with the Intel Fortran
compiler version 2021.1 with options
\mintinline{bash}{-O3 -xCORE-AVX512 -g -mkl=sequential -qopt-zmm-usage=high}.
The speedup with respect to the unoptimized kernel is presented in
figure~\ref{fig:speedup}, and reaches a factor of $19\times$ for the
largest system sizes. Performance analyzis of the mini-application
showed that at this stage we have reached 80\% of the single core peak
performance of the CPU core for this kernel.

The same strategy for kernel extraction of the codes and rewriting
will be applied to all other possible computational bottlenecks of QMC
simulations, and then the kernels will be implemented in the library.


\section{License}

The library is licensed under the open-source 3-clause BSD license to facilitate
its adoption in all quantum chemistry software, commercial or not.

\section{Dependencies}

Dependencies are critical: if a user is not able to install the
required dependencies, the user is not going to be able to use our
library, and solving the problem is out of our control. So the list of
external dependencies should be kept as small as possible. 
External libraries should be used \emph{only} if their use is
strongly justified, and if we are sure that the users will be able to
have access to them.

The dependencies needed to use pre-compiled versions of the library
are \ac{BLAS} and \ac{LAPACK}.

The dependencies needed to compile the code are
a C and a Fortran compiler, GNU make, \ac{BLAS} and \ac{LAPACK}, and
$\mu$nit\cite{munit} for building the unit tests.

The dependencies needed to create the \ac{HTML} documentation are
Emacs~26 and the package Emacs-htmlize.


\section{Continuous integration}

Continuous integration has been setup on the GitHub platform. Upon
pull request, the repository is automatically cloned on a virtual
machine. The source code is then extracted from the {\orgmode}
files and the library is compiled. Then the unit tests are compiled
and linked together with the library. If all the tests pass, the
pull request is considered valid, and can be merged.

When the code is updated, the documentation is automatically built and
the server hosting the documentation is updated, such that the web
site containing the documentation is always synchronized with the
latest version of the master branch of the GitHub repository.



\appendix
\section{Appendix: Documentation of the API}

In this section, we include as an example part of the documentation of
the library which is automatically generated from the {\orgmode}
files, in the current status. The rest of the documentation can be
found on the web site of the library\footnote{\url{https://trex-coe.github.io/qmckl}}.
The library is still at an early development stage. Up to now most of
the effort was made on preparing solid bases for the development of
the library, more related to system programming than scientific
programming (the context variable, memory allocation, conventions,
Makefiles, generation of the documentation, \textit{etc}). The actual
implementation of the kernels is in progress, and we refer the
reaer to section~\ref{sec:codesign} for more detail on our strategy.


\clearpage

\input{qmckl_context}
% TODO : include here documentation

